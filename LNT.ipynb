{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "mount_file_id": "15RMXqFEIYn16Q7uqlvxQaHozZ6adOo6E",
      "authorship_tag": "ABX9TyNqjEwBqiryGdNHJ+QaXV2Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KKKKeybird/LightNovelTranslate/blob/main/LNT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GoogleDrive挂载"
      ],
      "metadata": {
        "id": "D775ADEb6Kue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO9cIzHVuRty",
        "outputId": "756f14fc-99c4-439b-ad03-e43ffafd653f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 查看配置"
      ],
      "metadata": {
        "id": "mSTP2Rco7vlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /etc/lsb-release\n",
        "!uname -a\n",
        "!/opt/bin/nvidia-smi"
      ],
      "metadata": {
        "id": "LcKGPDefKAyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 环境配置"
      ],
      "metadata": {
        "id": "I5selgGp6RVd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 第一次使用下载模型"
      ],
      "metadata": {
        "id": "_zNVKpWMyOwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/oobabooga/text-generation-webui.git\n",
        "!wget https://huggingface.co/SakuraLLM/Sakura-14B-LNovel-v0.9b-GGUF/resolve/main/sakura-13b-lnovel-v0.9b-Q4_K_M.gguf\n",
        "!mv  /content/sakura-13b-lnovel-v0.9b-Q4_K_M.gguf /content/text-generation-webui/models/\n",
        "!pip install -r /content/text-generation-webui/requirements.txt\n",
        "!pip install ebooklib"
      ],
      "metadata": {
        "id": "9SI6f0jurb-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 端口转发"
      ],
      "metadata": {
        "id": "RSw-ZoPj6Xo_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 使用Tailscale内网穿透访问WebUI"
      ],
      "metadata": {
        "id": "Z4LznG6x0Aol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://pkgs.tailscale.com/stable/ubuntu/bionic.gpg | sudo apt-key add -\n",
        "!curl -fsSL https://pkgs.tailscale.com/stable/ubuntu/bionic.list | sudo tee /etc/apt/sources.list.d/tailscale.list\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install tailscale\n",
        "!rm -rf /tmp/tailscaled\n",
        "!mkdir -p /tmp/tailscaled\n",
        "!chown irc.irc /tmp/tailscaled\n",
        "!rm -rf /var/run/tailscale\n",
        "!mkdir -p /var/run/tailscale\n",
        "!chown irc.irc /var/run/tailscale\n",
        "!cp /var/lib/tailscaled/tailscaled.state /tmp/tailscaled/tailscaled.state\n",
        "!chown irc.irc /tmp/tailscaled/tailscaled.state\n",
        "!nohup sudo -u irc tailscaled --tun=userspace-networking --socks5-server=localhost:1055 --state=/tmp/tailscaled/tailscaled.state --socket=/var/run/tailscale/tailscaled.sock --port 41641 &\n",
        "!until tailscale up; do sleep 1; done"
      ],
      "metadata": {
        "id": "akYEcclEMG4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup sudo -u irc tailscaled --tun=userspace-networking --socks5-server=localhost:1055 --state=/tmp/tailscaled/tailscaled.state --socket=/var/run/tailscale/tailscaled.sock --port 41641 &\n",
        "!until tailscale up; do sleep 1; done\n",
        "!curl --socks5-hostname localhost:1055 http://100.100.1.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnghsARjKZEn",
        "outputId": "59facf2a-703e-4680-aa0b-a92391e38b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            "curl: (97) connection to proxy closed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 文件目录格式\n",
        "- content\n",
        "-- 原文.epub\n",
        "-- 替换字典.json\n"
      ],
      "metadata": {
        "id": "JE7y2B8Ry1o7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 服务启动"
      ],
      "metadata": {
        "id": "mtFp74NI6b1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup bash /content/text-generation-webui/start_linux.sh &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syEpvofsrGst",
        "outputId": "b163a886-e2c8-4c6f-adab-3e8f0495f63f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 服务启动后访问\"http://{tailscale_ip}:7860\"，在Session页面开启api并Apply and Restart，重启后在Model里加载模型"
      ],
      "metadata": {
        "id": "1YsVVlal0K_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 翻译脚本启动"
      ],
      "metadata": {
        "id": "Wzi_TwUp86LL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "import sys\n",
        "import json\n",
        "import unicodedata\n",
        "import os\n",
        "import ebooklib\n",
        "from bs4 import BeautifulSoup\n",
        "from ebooklib import epub\n",
        "\n",
        "\n",
        "def strQ2B(ustring):\n",
        "    \"\"\"把字符串半角转全角\"\"\"\n",
        "    ss = []\n",
        "    for s in ustring:\n",
        "        rstring = \"\"\n",
        "        for uchar in s:\n",
        "            inside_code = ord(uchar)\n",
        "            if inside_code == 12288:  # 全角空格直接转换\n",
        "                inside_code = 32\n",
        "            elif (inside_code >= 65281 and inside_code <= 65374):  # 全角字符（除空格）根据关系转化\n",
        "                inside_code -= 65248\n",
        "            rstring += chr(inside_code)\n",
        "        ss.append(rstring)\n",
        "    return ''.join(ss)\n",
        "\n",
        "\n",
        "#处理epub文件获得html解析文本\n",
        "if not os.path.exists(\"原文.epub\"):\n",
        "    print(f\"原文.epub不存在\")\n",
        "    sys.exit(1)\n",
        "\n",
        "script_folder = os.path.dirname(os.path.abspath(__file__))\n",
        "\n",
        "book = epub.read_epub(os.path.join(script_folder,\"原文.epub\"))\n",
        "original_htmls=[]\n",
        "for item in book.get_items():\n",
        "    if item.get_type() == ebooklib.ITEM_DOCUMENT:\n",
        "        soup=BeautifulSoup(item.get_content(),'html')\n",
        "        text=[tag.extract() for tag in soup.select('rt')]\n",
        "        original_htmls.append(strQ2B(soup.get_text()))\n",
        "\n",
        "\n",
        "#处理名词替换\n",
        "\n",
        "\n",
        "def is_empty(filename):\n",
        "    try:\n",
        "        with open(filename, 'r', encoding='utf-8') as file:\n",
        "            data = json.load(file)\n",
        "        return isinstance(data, dict) and not bool(data)\n",
        "    except (FileNotFoundError, json.JSONDecodeError):\n",
        "        return False\n",
        "\n",
        "\n",
        "replacements_file = os.path.join(script_folder, '特殊名词替换.json')\n",
        "\n",
        "if is_empty(replacements_file):\n",
        "    print(\"特殊名词替换文件内部为空，请手动配置\")\n",
        "    print(\"exiting\")\n",
        "else:\n",
        "    with open('替换字典.json', 'r', encoding='utf-8') as file:\n",
        "        replacement_dict = json.load(file)\n",
        "        # 对替换字典中的值进行全角转换为半角\n",
        "        for key, value in replacement_dict.items():\n",
        "            replacement_dict[key] = unicodedata.normalize('NFKC', value)\n",
        "\n",
        "    htmls=[]\n",
        "    for content in original_htmls:\n",
        "\n",
        "        for old_text, new_text in replacement_dict.items():\n",
        "            content = content.replace(old_text, new_text)\n",
        "        if content.isspace()==False:\n",
        "            htmls.append(content)\n",
        "\n",
        "print(\"特殊名词替换任务完成。\")\n",
        "\n",
        "APIURL = \"http://127.0.0.1:5000\" + \"/v1/chat/completions\"\n",
        "\n",
        "\n",
        "def translate_text(text, temperature=0.2, frequency_penalty=0.0):\n",
        "    attempts = 0\n",
        "    max_attempts = 5\n",
        "    last_exception = None\n",
        "    while attempts < max_attempts:\n",
        "        try:\n",
        "            url = APIURL\n",
        "            prompt_with_text = f\"将下面的日文文本翻译成中文：{text}\"\n",
        "            messages = [{\"role\": \"user\", \"content\": prompt_with_text}]\n",
        "            payload = {\n",
        "                \"messages\": messages,\n",
        "                \"max_tokens\": 1024,\n",
        "                \"temperature\": temperature,\n",
        "                \"mode\": \"instruct\",\n",
        "                \"instruction_template\": \"ChatML\",\n",
        "                \"frequency_penalty\": frequency_penalty,\n",
        "                \"negative_prompt\": \"你是一个轻小说翻译模型，可以流畅通顺地以日本轻小说的风格将日文翻译成简体中文，并联系上下文正确使用人称代词，不擅自添加原文中没有的代词。\",\n",
        "                \"stop\": [\"\\n###\", \"\\n\\n\", \"[PAD151645]\", \"<|im_end|>\"]\n",
        "            }\n",
        "            response = requests.post(url, json=payload)\n",
        "            if response.status_code == 200:\n",
        "                translated_text = response.json()['choices'][0]['message']['content'].strip()\n",
        "                return translated_text\n",
        "            else:\n",
        "                attempts += 1\n",
        "                time.sleep(1)\n",
        "        except Exception as e:\n",
        "            print(f\"尝试 {attempts + 1}/{max_attempts} 次失败: {e}\")\n",
        "            attempts += 1\n",
        "            time.sleep(1)\n",
        "            last_exception = e\n",
        "    print(f\"API调用出错: {last_exception}\")\n",
        "    raise Exception(f\"API调用连续失败{max_attempts}次，停止脚本。\")\n",
        "\n",
        "\n",
        "def print_progress_bar(iteration, total, prefix='', suffix='', length=50, fill='█'):\n",
        "    percent = \"{0:.1f}\".format(100 * (iteration / float(total)))\n",
        "    filled_length = int(length * iteration // total)\n",
        "    bar = fill * filled_length + '-' * (length - filled_length)\n",
        "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end=\"\\r\")\n",
        "    # 输出换行\n",
        "    if iteration == total:\n",
        "        print()\n",
        "\n",
        "\n",
        "def split_paragraphs(text):\n",
        "    paragraphs = text.split('\\n')\n",
        "    combined_paragraphs = []\n",
        "    current_paragraph = \"\"\n",
        "\n",
        "    for paragraph in paragraphs:\n",
        "        if not paragraph.strip():\n",
        "            if current_paragraph:\n",
        "                combined_paragraphs.append(current_paragraph)\n",
        "                current_paragraph = \"\"  # 重置累积段落\n",
        "            combined_paragraphs.append(\"\")  # 分隔\n",
        "        else:\n",
        "            # 合并逻辑\n",
        "            if len(current_paragraph + '\\n' + paragraph) < 600:\n",
        "                current_paragraph += ('\\n' + paragraph if current_paragraph else paragraph)\n",
        "            else:\n",
        "                if not current_paragraph:\n",
        "                    current_paragraph = paragraph\n",
        "                else:\n",
        "                    combined_paragraphs.append(current_paragraph)\n",
        "                    current_paragraph = paragraph\n",
        "\n",
        "    # 添加最后累积的段落\n",
        "    if current_paragraph:\n",
        "        combined_paragraphs.append(current_paragraph)\n",
        "\n",
        "    return combined_paragraphs\n",
        "\n",
        "\n",
        "def main():\n",
        "    for j,html in enumerate(htmls):\n",
        "        paragraphs = split_paragraphs(html)\n",
        "\n",
        "        translated_paragraphs = []\n",
        "        total_paragraphs = len(paragraphs)\n",
        "        try:\n",
        "            for i, paragraph in enumerate(paragraphs):\n",
        "                if not paragraph.strip():\n",
        "                    translated_paragraphs.append(paragraph)\n",
        "                else:\n",
        "                    print('\\n')\n",
        "                    print(f'正在翻译：\\n{paragraph}')\n",
        "                    translated_text = translate_text(paragraph)\n",
        "                    print('\\n')\n",
        "                    print(f'翻译完成：\\n{translated_text}')\n",
        "                    if translated_text:\n",
        "                        translated_paragraphs.append(translated_text)\n",
        "                    else:\n",
        "                        print(\"翻译失败，跳过该段落。\")\n",
        "                        translated_paragraphs.append(paragraph)  # 保留原文以防万一\n",
        "                print_progress_bar(i + 1, total_paragraphs, prefix='进度:', suffix='完成', length=50)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            with open('翻译完成'+str(j)+'.txt', 'w', encoding='utf-8') as file:\n",
        "                file.write('\\n'.join(translated_paragraphs))\n",
        "            with open('断点记录'+str(j)+'.txt', 'w', encoding='utf-8') as file:\n",
        "                remaining_paragraphs = paragraphs[len(translated_paragraphs):]\n",
        "                file.write('\\n'.join(remaining_paragraphs))\n",
        "            return\n",
        "\n",
        "        with open('翻译完成'+str(j)+'.txt', 'w', encoding='utf-8') as file:\n",
        "            file.write('\\n'.join(translated_paragraphs))\n",
        "            print(\"翻译完成\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "3dfVw3yTzDh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 打包文件"
      ],
      "metadata": {
        "id": "6wgH7FSVpDZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/翻译.zip\n",
        "!zip -r 翻译.zip /content/翻译完成*\n",
        "!rm -rf /content/翻译完成*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YL6chwZOpGjv",
        "outputId": "65ded116-2519-46ce-ff9b-fce4c885c28d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/翻译完成0.txt (deflated 1%)\n",
            "  adding: content/翻译完成10.txt (deflated 53%)\n",
            "  adding: content/翻译完成11.txt (deflated 51%)\n",
            "  adding: content/翻译完成12.txt (deflated 56%)\n",
            "  adding: content/翻译完成13.txt (deflated 50%)\n",
            "  adding: content/翻译完成14.txt (deflated 54%)\n",
            "  adding: content/翻译完成15.txt (deflated 54%)\n",
            "  adding: content/翻译完成16.txt (deflated 49%)\n",
            "  adding: content/翻译完成17.txt (deflated 30%)\n",
            "  adding: content/翻译完成18.txt (deflated 56%)\n",
            "  adding: content/翻译完成19.txt (deflated 47%)\n",
            "  adding: content/翻译完成1.txt (deflated 18%)\n",
            "  adding: content/翻译完成20.txt (deflated 47%)\n",
            "  adding: content/翻译完成21.txt (deflated 37%)\n",
            "  adding: content/翻译完成22.txt (deflated 6%)\n",
            "  adding: content/翻译完成23.txt (deflated 11%)\n",
            "  adding: content/翻译完成24.txt (deflated 14%)\n",
            "  adding: content/翻译完成2.txt (stored 0%)\n",
            "  adding: content/翻译完成3.txt (deflated 28%)\n",
            "  adding: content/翻译完成4.txt (deflated 36%)\n",
            "  adding: content/翻译完成5.txt (deflated 53%)\n",
            "  adding: content/翻译完成6.txt (deflated 50%)\n",
            "  adding: content/翻译完成7.txt (deflated 56%)\n",
            "  adding: content/翻译完成8.txt (deflated 20%)\n",
            "  adding: content/翻译完成9.txt (deflated 55%)\n"
          ]
        }
      ]
    }
  ]
}